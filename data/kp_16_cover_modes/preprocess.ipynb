{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-01 03:21:53.803241: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import sys\n",
    "import tempfile\n",
    "import tqdm\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_X(X_path):\n",
    "    file = open(X_path, 'r')\n",
    "    X_ = np.array(\n",
    "        [elem for elem in [\n",
    "            row.split(',')[:] for row in file\n",
    "        ]],\n",
    "        dtype=np.float32\n",
    "    )\n",
    "    X_=X_[:,:-1]\n",
    "    print(\"X_.shape is \",str(X_.shape))\n",
    "    file.close()\n",
    "    return X_\n",
    "def load_Y(Y_path):\n",
    "    file = open(Y_path, 'r')\n",
    "    Y_ = np.array(\n",
    "        [elem for elem in [\n",
    "            row.split(',')[:] for row in file\n",
    "        ]],\n",
    "        dtype=np.float32\n",
    "    )\n",
    "    Y_=Y_[:,-1]\n",
    "    print(\"Y_shape is\" ,str(Y_.shape))\n",
    "    file.close()\n",
    "    return Y_\n",
    "def load_filepath(path):\n",
    "    file = open(path, 'r')\n",
    "    fp_=[]\n",
    "    for row in file:\n",
    "      temp_fp_=row.split(',')[-1]\n",
    "      fp_.append(temp_fp_)\n",
    "    print(\"Length of file_path is: \",len(fp_))\n",
    "    file.close()\n",
    "    return fp_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is for spliting into train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Read the csv file into a pandas dataframe\n",
    "spliting_folder=\"/ske/data/kp_16_cover_modes/cover2\"\n",
    "ori_file=\"cover2.csv\"\n",
    "train_file=\"traincover2.csv\"\n",
    "test_file=\"testcover2.csv\"\n",
    "df = pd.read_csv(os.path.join(spliting_folder,ori_file), header=None)\n",
    "\n",
    "# Split the dataframe into X (features) and y (class)\n",
    "X = df.iloc[:, :-2] # All columns except the last two\n",
    "y = df.iloc[:, -2] # The second last column\n",
    "\n",
    "# Split the data into train and test sets with a 7/3 ratio and stratified by the class\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Concatenate the features and class columns for the train and test sets\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# Write the train and test sets to csv files\n",
    "train.to_csv(os.path.join(spliting_folder,train_file), index=False, header=False)\n",
    "test.to_csv(os.path.join(spliting_folder,test_file), index=False, header=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Read the csv file into a pandas dataframe\n",
    "spliting_folder=\"/ske/Kinetic-GAN/output/gan_sample\"\n",
    "ori_file=\"gan_sample.csv\"\n",
    "train_file=\"train_gan_sample.csv\"\n",
    "test_file=\"test_gan_sample.csv\"\n",
    "df = pd.read_csv(os.path.join(spliting_folder,ori_file), header=None)\n",
    "\n",
    "# Split the dataframe into X (features) and y (class)\n",
    "X = df.iloc[:, :-1] # All columns except the last two\n",
    "y = df.iloc[:, -1] # The second last column\n",
    "\n",
    "# Split the data into train and test sets with a 7/3 ratio and stratified by the class\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Concatenate the features and class columns for the train and test sets\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# Write the train and test sets to csv files\n",
    "train.to_csv(os.path.join(spliting_folder,train_file), index=False, header=False)\n",
    "test.to_csv(os.path.join(spliting_folder,test_file), index=False, header=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
